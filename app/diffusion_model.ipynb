{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc443e2-bb05-455d-9506-9ddf4ea06a77",
   "metadata": {},
   "source": [
    "## StableDiffusion Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4699e74a-6752-4b6a-9237-d0cb88cc94c3",
   "metadata": {},
   "source": [
    "설치 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b9682f-b3ac-477b-89b4-61ed6bc16719",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai==1.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c303062-4c66-4e88-9a1f-87c24e91e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install diffusers accelerate safetensors transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe647e4-a414-4ea4-b7a3-717036db4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install compel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16842283-f20f-4b74-8b17-be964776914d",
   "metadata": {},
   "source": [
    "프롬프트 생성 클래스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbc3568-2a43-4e89-96b9-c50a5a2d9189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12326/4087964187.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-01-31 09:07:16.377593: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-31 09:07:16.377631: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-31 09:07:16.378255: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-31 09:07:16.382390: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import hmac, hashlib\n",
    "from pytz import timezone\n",
    "from keybert import KeyBERT\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "import openai\n",
    "\n",
    "# gpt api 관련 변수\n",
    "openai.api_key = 'GPT KEY'\n",
    "\n",
    "# papago api 관련 변수\n",
    "papago_client_id = \"파파고 클라이언트\"  # 개발자 센터에서 발급받은 클라이언트 ID\n",
    "papago_client_secret = '파파고 시크릿'  # 개발자 센터에서 발급받은 클라이언트 시크릿\n",
    "papago_url = 'https://openapi.naver.com/v1/papago/n2mt'\n",
    "papago_headers = {\n",
    "    'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n",
    "    'X-Naver-Client-Id': papago_client_id,\n",
    "    'X-Naver-Client-Secret': papago_client_secret,\n",
    "}\n",
    "\n",
    "\n",
    "class PromptEnglish:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        \n",
    "    def gpt(self):\n",
    "        input_message = f'\"{self.text}\"와 유사한 문장 10개만 생성해줘. 디테일한 내용이 더 추가되어도 괜찮아'\n",
    "        \n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo-1106\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": input_message}\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            improved_text = response.choices[0].message.content\n",
    "            print(\"improved_text\", improved_text)\n",
    "            \n",
    "            sentences = [sentence.strip() for sentence in improved_text.split('\\n')]\n",
    "            # print(sentences)            \n",
    "            augments = []\n",
    "            for sentence in sentences:\n",
    "                temp = sentence.split('.')\n",
    "                hap = ''\n",
    "                for i in range(len(temp)):\n",
    "                    if i == 0:\n",
    "                        pass\n",
    "                    elif i == len(temp)-1:\n",
    "                        hap += temp[i] \n",
    "                    else:\n",
    "                        hap = hap + temp[i] + '.'\n",
    "                augments.append(hap)\n",
    "\n",
    "            # 입력값도 추가\n",
    "            augments.append(self.text)\n",
    "            return augments\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return str(e)\n",
    "\n",
    "    @classmethod\n",
    "    def papago_translation(cls, text_list):\n",
    "        translated_texts = []\n",
    "        \n",
    "        # 한국어, 영어로 변환\n",
    "        for text in text_list:\n",
    "            data = {\n",
    "                'source': 'ko',\n",
    "                'target': 'en',\n",
    "                'text': text,\n",
    "            }\n",
    "\n",
    "            response = requests.post(papago_url, headers=papago_headers, data=data)\n",
    "            result = response.json()\n",
    "\n",
    "            if 'errorMessage' in result:\n",
    "                return result['errorMessage']\n",
    "\n",
    "            else:\n",
    "                translated_text = result['message']['result']['translatedText']\n",
    "                translated_texts.append(translated_text)\n",
    "            \n",
    "            base_prompt = translated_texts[-1]\n",
    "                \n",
    "        return translated_texts, base_prompt\n",
    "    \n",
    "    # BERT모델을 활용한 키워드, 가중치 추출\n",
    "    @classmethod\n",
    "    def bert(cls, text_list):\n",
    "        bow = []\n",
    "        \n",
    "        extractor = KeyBERT(\"all-mpnet-base-v2\")\n",
    "        \n",
    "        for i in range(len(text_list)):\n",
    "            keywords = extractor.extract_keywords(text_list[i], stop_words='english')\n",
    "            bow.append(keywords)\n",
    "            \n",
    "        new_bow = []\n",
    "        \n",
    "        for i in range(0, len(bow)):\n",
    "            for j in range(len(bow[i])):\n",
    "                new_bow.append(bow[i][j])\n",
    "                \n",
    "        df = pd.DataFrame(new_bow, columns=['keyword', 'weight'])\n",
    "        \n",
    "        # GROUPBY\n",
    "        # 동일 keyword에 대해서 가중치 중앙값 추출\n",
    "        weight_df = df.groupby('keyword').agg('median').sort_index()\n",
    "        # 동일 keyword의 count 추출 후, 칼럼명 count로 변환\n",
    "        count_df = df.groupby('keyword').agg('count').sort_index()\n",
    "        count_df.rename(columns={'weight':'count'}, inplace=True)\n",
    "        \n",
    "        # keyword기준 두 df 합치기\n",
    "        result_df = weight_df.join(count_df)\n",
    "        result_df.sort_values('count', ascending=False, inplace=True)\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    @classmethod\n",
    "    ## +로 가중치 부여한 프롬프트 \n",
    "    def prompt_weighting(cls, dataframe, text_list):\n",
    "        \n",
    "        # 중요도 높은 단어 상위 5개 추출\n",
    "        top_weight_word = dataframe.head(5).index.values\n",
    "        \n",
    "        weight_dict = {}\n",
    "        prompt = \"\"\n",
    "        \n",
    "        # 단어:가중치 형태의 딕셔너리 생성\n",
    "        for i in range(len(top_weight_word)):\n",
    "            weight_dict[top_weight_word[i]] = '+' * (5-i)\n",
    "\n",
    "        # 단어 옆에 가중치 추가\n",
    "        for text in text_list:\n",
    "            indexs = []\n",
    "            for key, val in weight_dict.items():\n",
    "                if key in text:\n",
    "                    index = text.find(key)\n",
    "                    \n",
    "                    if index != -1:\n",
    "                        text = text[:index + len(key)] + val + text[index + len(key):]\n",
    "            prompt += text\n",
    "        \n",
    "        # 마침표 제거. 쉼표로 프롬포트 연결\n",
    "        if \".\" in prompt:\n",
    "            prompt.replace(\".\", \", \")\n",
    "        \n",
    "        return prompt[:-2]\n",
    "\n",
    "    @classmethod \n",
    "    def positive_prompt(cls, df):\n",
    "        result = ''\n",
    "        keyword = df.index.values\n",
    "        \n",
    "        for i in range(len(keyword)):\n",
    "            if i != len(keyword)-1:\n",
    "                result = result + keyword[i] + '+++, '\n",
    "            else:\n",
    "                result = result + keyword[i] + '+++'\n",
    "                \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014fa30f-8bb3-49cf-9917-9c78f1d43063",
   "metadata": {},
   "source": [
    "prompt 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea3826-f665-4164-8698-a06d2012d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬포트 예시\n",
    "input = '학사복을 입고 꽃다발을 들고 있는 금발 머리의 여자는 교문 앞에서 부모님과 함께 사진을 찍고 있고, 교문 뒤에는 학교의 상징인 큰 시계탑이 있다.'\n",
    "myprompt = PromptEnglish(input)\n",
    "\n",
    "result = myprompt.myGPT()\n",
    "translated, base_prompt = myprompt.papago_translation(result)\n",
    "print('prompt: ', base_prompt)\n",
    "\n",
    "df = myprompt.bert(translated)\n",
    "print(df)\n",
    "\n",
    "prompt_2 = myprompt.positive_prompt(df)\n",
    "print('prompt_2: ', prompt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e3df1d",
   "metadata": {},
   "source": [
    "\n",
    "prompt: 'A blond woman wearing a school uniform and holding a bouquet of flowers is taking a picture with her parents in front of the school gate, and behind the school gate is a large clock tower, the symbol of the school.'\n",
    "\n",
    "prompt_2: 'school+++, graduation+++, commemorative+++, graduates+++, garden+++, blond+++, students+++, hat+++, gate+++, birds+++, ceremony+++, celebrate+++, blonde+++, women+++, flowers+++, gathering+++, building+++, lake+++, parents+++, photo+++, photos+++, picture+++, bouquet+++, tower+++, uniform+++'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d62f09-3bd5-4b8a-a7a7-0c6467f9f653",
   "metadata": {},
   "source": [
    "이미지 저장 시에 사용하는 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac4eec-fdd3-4321-bca7-5d4fe29e5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "def generate_filename(model):\n",
    "    korea_tz = pytz.timezone('Asia/Seoul')\n",
    "    utc_now = datetime.utcnow()\n",
    "    korea_now = utc_now.replace(tzinfo=pytz.utc).astimezone(korea_tz)\n",
    "    korea_now = korea_now.strftime('%H:%M')\n",
    "    # file_name = \"/tf/notebook/SD_result_img/\" + model + str(korea_now) + \".png\"\n",
    "    return \"/tf/notebook/SD_result_img/\" + model + str(korea_now) + \".png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c461d77-05c0-4cb4-bb89-fa54d46ebc8a",
   "metadata": {},
   "source": [
    "이미지 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785d350-1acb-47d3-af6e-7e4bbc24084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import  StableDiffusionXLPipeline, DDIMScheduler, DDPMScheduler\n",
    "from diffusers.utils import load_image\n",
    "import torch, gc\n",
    "import pytz\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print('now cache is empty')\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", \n",
    "    torch_dtype=torch.float16, \n",
    "    variant=\"fp16\", \n",
    "    use_safetensors=True\n",
    ")\n",
    "pipe.to('cuda')\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "positive_prompt = 'realism++, realistic++, super-detailed++, true-to-life++, best quality++, balanced++, well-defined++, Modernist++, well-defined facial features++, detailed faces++'\n",
    "negative_prompt = 'CG, wallpaper, animation, anime, doll, disney, cartoons, cropped, misshapen, blurry, pixiv, artstation, desaturated, abstract, surreal, pixelated, noisy, pop art, no faces, no objects, no landscape, mutilated, disfigured, ugly, deformed, clear visibility of faces, no abstract faces, shadows on faces'\n",
    "\n",
    "prompt_2 = prompt_2 + positive_prompt\n",
    "\n",
    "n = 120\n",
    "m = 7.5\n",
    "\n",
    "# generator=torch.manual_seed(1)\n",
    "image = pipe(prompt=base_prompt, prompt_2=prompt_2, negative_prompt=negative_prompt, num_inference_steps=n, guidance_scale=m).images[0]\n",
    " \n",
    "# # file_name = generate_filename('sdxl-base-1.0-DDIM', n, m)\n",
    "# # image.save(file_name)\n",
    "# image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
